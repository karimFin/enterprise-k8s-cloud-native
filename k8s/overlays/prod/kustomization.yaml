apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: myapp-production

resources:
  - ../../base

patches:
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: backend
      spec:
        replicas: 1
        template:
          spec:
            containers:
              - name: backend
                resources:
                  requests:
                    cpu: 250m
                    memory: 256Mi
                  limits:
                    cpu: "1"
                    memory: 1Gi
            imagePullSecrets:
              - name: ghcr-secret
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: frontend
      spec:
        replicas: 1
        template:
          spec:
            imagePullSecrets:
              - name: ghcr-secret
  - patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: backend-hpa
      spec:
        minReplicas: 1
        maxReplicas: 1
  - patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: frontend-hpa
      spec:
        minReplicas: 1
        maxReplicas: 1
  - patch: |-
      apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: postgres
      spec:
        template:
          spec:
            imagePullSecrets:
              - name: ghcr-secret
  - patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: frontend
      spec:
        type: LoadBalancer

configMapGenerator:
  - name: app-config
    behavior: merge
    literals:
      - NODE_ENV=production
      - LOG_LEVEL=warn
      - CORS_ORIGIN=https://myapp.example.com
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=tasks
      - LLM_PROVIDER=openai
      - LLM_MODEL=gpt-4o-mini
      - LLM_MODEL_FAST=gpt-4o-mini
      - LLM_MODEL_ACCURATE=gpt-4o
      - LLM_EMBED_MODEL=text-embedding-3-small
      - LLM_API_BASE=https://api.openai.com/v1
      - LLM_VECTOR_SIZE=1536
      - LLM_ROUTING=length
      - LLM_ROUTING_MAX_CHARS=200
      - LLM_RATE_LIMIT_WINDOW_MS=60000
      - LLM_RATE_LIMIT_MAX=30
      - LLM_COST_INPUT_PER_1K=0.00015
      - LLM_COST_OUTPUT_PER_1K=0.0006
      - LLM_EMBED_COST_PER_1K=0.00002

images:
  - name: backend
    newName: ghcr.io/karimfin/myapp-backend
    newTag: latest
  - name: frontend
    newName: ghcr.io/karimfin/myapp-frontend
    newTag: latest
